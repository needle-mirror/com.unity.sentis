> [!NOTE]
> Sentis is now called Inference Engine. The documentation has moved to `https://docs.unity3d.com/Packages/com.unity.ai.inference@latest`. Refer to the new location for the latest updates and guidance. Make sure to update your bookmarks and references accordingly.

# Run an imported model

Use Sentis to run an imported model with input data and get the output data.

|Page|Description|
|-|-|
|[How Sentis runs a model](how-sentis-runs-a-model.md)|Understand how Sentis runs a model.|
|[Create input for a model](create-an-input-tensor.md)|Create input data for a model from an array or a texture.|
|[Convert a texture to a tensor](convert-texture-to-tensor.md)|Convert a texture to a tensor, and override texture shape and layout.|
|[Create an engine to run a model](create-an-engine.md)|Create a worker, which is the engine that breaks the model down into executable tasks.|
|[Run a model](run-a-model.md)|Run a model in a single frame.|
|[Split inference over multiple frames](split-inference-over-multiple-frames.md)|Run a model a layer at a time.|
|[Use a command buffer](use-command-buffer.md)|Use a command buffer to create a queue of Sentis commands, then run the commands on the GPU later.|
|[Get output from a model](get-the-output.md)|Get and log the output data from a model.|
|[Read output asynchronously](read-output-async.md)|Read the output data from a model asynchronously.|
|[Use output data](use-model-output.md)|Convert the output data to an array or a texture, copy the data to the screen.|
|[Manage memory](manage-memory.md)|Call `Dispose` on workers and tensors.|
